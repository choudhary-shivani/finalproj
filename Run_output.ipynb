{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Run_output.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lbswQVXvO2P"
      },
      "source": [
        "import gc\n",
        "import time\n",
        "import os, joblib\n",
        "os.chdir('/content/drive/MyDrive/finalproj')\n",
        "import _pickle as cpickle\n",
        "import numpy as np\n",
        "\n",
        "from utils import read_topics_as_utterances\n",
        "from pyserini.search import SimpleSearcher\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "from hqe import HQE\n",
        "from pqe import PQE\n",
        "from subprocess import Popen, PIPE\n",
        "from ranker import rerank\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "cast_index_loc = './index-cast2019'\n",
        "cast_data_loc = './treccastweb/2020/2020_automatic_evaluation_topics_v1.0.json'\n",
        "tfidf_loc = './idf_lemmatized_counter.pkl'\n",
        "\n",
        "# Data Related\n",
        "training_topics = './treccastweb/2019/data/training/train_topics_v1.0.json'\n",
        "evaluation_topics = './treccastweb/2019/data/evaluation/evaluation_topics_v1' \\\n",
        "                    '.0.json'\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__L-khhswd2_"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsDkoVmGvelc"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "!pip install pyserini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdcmnibxvO2X"
      },
      "source": [
        "config = {\n",
        "    'cardinality': 10,\n",
        "    'verbose': True,\n",
        "    'hqe': {\n",
        "        'qt_thresh': 3,\n",
        "        'st_thresh': 3,\n",
        "        'q_thresh': 12,\n",
        "        'last_k': 3,\n",
        "        'use_orig_for_query': True\n",
        "    },\n",
        "    'pqe': {\n",
        "        'top_k_documents': 10,\n",
        "        'top_k_tokens': 5,\n",
        "    },\n",
        "    'ranker':\n",
        "        {\n",
        "            'passage_max_len': 448,\n",
        "            'query_max_len': 64\n",
        "        }\n",
        "}\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avgf4SKtvO2Z"
      },
      "source": [
        "class Pipeline(object):\n",
        "    def __init__(self, cfg):\n",
        "        self.cfg = cfg\n",
        "        self.cardinality = cfg['cardinality']\n",
        "\n",
        "        self.backend_engine = None\n",
        "        self.idf = None\n",
        "        self.expansion_pipeline = None\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.ranker_pipeline = None\n",
        "        self.prepare_pipeline(cfg)\n",
        "        self.query_dict = {}\n",
        "\n",
        "    def prepare_pipeline(self, cfg):\n",
        "\n",
        "        print(f'Loading Backed PySerini Engine from {cast_index_loc}')\n",
        "        self.backend_engine = SimpleSearcher(cast_index_loc)\n",
        "\n",
        "        print(f'Loading IDF values from {tfidf_loc}')\n",
        "        start = time.time()\n",
        "        gc.disable()\n",
        "        # self.idf = joblib.load(tfidf_loc)\n",
        "        with open(tfidf_loc, 'rb') as f:\n",
        "            self.idf = cpickle.load(f)\n",
        "        gc.enable()\n",
        "        print(\"Loading completed in {} sec.\".format(time.time() - start))\n",
        "        print(f'Loading BERT reranker and tokenizer')\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            \"amberoad/bert-multilingual-passage-reranking-msmarco\")\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            \"amberoad/bert-multilingual-passage-reranking-msmarco\")\n",
        "\n",
        "        components = []\n",
        "        if 'hqe' in cfg:\n",
        "            print(f'Adding HQE module to pipeline')\n",
        "            hqe_cfg = cfg['hqe']\n",
        "            hqe = HQE(self.backend_engine, hqe_cfg)\n",
        "            components.append(hqe)\n",
        "\n",
        "        if 'pqe' in cfg:\n",
        "            print(f'Adding PQE module to pipeline')\n",
        "            pqe_cfg = cfg['pqe']\n",
        "            pqe = PQE(\n",
        "                ir_engine=self.backend_engine,\n",
        "                idf=self.idf,\n",
        "                top_k_documents=pqe_cfg['top_k_documents'],\n",
        "                top_k_tokens=pqe_cfg['top_k_tokens']\n",
        "            )\n",
        "            components.append(pqe)\n",
        "\n",
        "        if 'ranker' in cfg:\n",
        "            print(f'Adding Reranker module to pipeline')\n",
        "            ranker_cfg = cfg['ranker']\n",
        "            ranker = rerank(\n",
        "                ir_engine=self.backend_engine,\n",
        "                passage_max_len=ranker_cfg['passage_max_len'],\n",
        "                query_max_len=ranker_cfg['query_max_len'],\n",
        "                tokenizer=self.tokenizer,\n",
        "                model=self.model,\n",
        "                verbose=cfg['verbose']\n",
        "            )\n",
        "            self.ranker_pipeline = ranker\n",
        "\n",
        "        self.expansion_pipeline = components\n",
        "        print('Pipeline load completed.')\n",
        "\n",
        "    def query_expansion(self, utterances):\n",
        "\n",
        "        if len(self.expansion_pipeline) == 0:\n",
        "            return utterances\n",
        "\n",
        "        expanded_queries = utterances\n",
        "        # change the expanded_queries[idx] to utterace[idx] if you want to\n",
        "        # run just on PQE terms. Leave at it is if you want to run on the\n",
        "        # both sets\n",
        "        for module in self.expansion_pipeline:\n",
        "            extension_sets = module.expand_queries(expanded_queries)\n",
        "            expanded_queries = [\n",
        "                expanded_queries[idx] + \" \" + \" \".join(extension_sets[idx])\n",
        "                for idx in range(len(utterances))\n",
        "            ]\n",
        "            self.query_dict[module] = extension_sets\n",
        "        with open('post_eval.txt', 'a') as f:\n",
        "            f.write(\"{} {} {}\".format(utterances, '\\n\\n\\n', self.query_dict))\n",
        "        return expanded_queries\n",
        "\n",
        "    def query_execution(self, utterances):\n",
        "        results = []\n",
        "\n",
        "        for query in utterances:\n",
        "            hits = self.backend_engine.search(query, k=20)\n",
        "            results.append(\n",
        "                [hit.docid for hit in hits]\n",
        "            )\n",
        "        return results\n",
        "\n",
        "    def passage_reranker(self, utterances, results):\n",
        "        reranked_output = []\n",
        "        for query, result in zip(utterances, results):\n",
        "            # query = ' '.join(set(query.split()))\n",
        "            # print(query)\n",
        "            reranked_output.append(self.ranker_pipeline.rerank(query, result))\n",
        "        return reranked_output\n",
        "\n",
        "    def execute(self, utterances):\n",
        "        queries = self.query_expansion(utterances)\n",
        "        # print(queries)\n",
        "        results = self.query_execution(queries)\n",
        "        reranked = self.passage_reranker(queries,\n",
        "                                         results)\n",
        "\n",
        "        return results, reranked"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWGPH-n1vO2e"
      },
      "source": [
        "def optim(qt_thresh=3, st_thresh=3, q_thresh=12, top_k_documents=10,\n",
        "          top_k_token=5):\n",
        "    config = {\n",
        "    'cardinality': 10,\n",
        "    'verbose': False,\n",
        "    'hqe': {\n",
        "        'qt_thresh': qt_thresh,\n",
        "        'st_thresh': st_thresh,\n",
        "        'q_thresh': q_thresh,\n",
        "        'last_k': 3,\n",
        "        'use_orig_for_query': True\n",
        "    },\n",
        "    'pqe': {\n",
        "        'top_k_documents': top_k_documents,\n",
        "        'top_k_tokens': top_k_token,\n",
        "    },\n",
        "    'ranker':\n",
        "        {\n",
        "            'passage_max_len': 448,\n",
        "            'query_max_len': 64\n",
        "        }\n",
        "    }\n",
        "\n",
        "    pipeline = Pipeline(config)\n",
        "    train_utterances = read_topics_as_utterances(training_topics)\n",
        "    extn = \"{}_{}_{}_{}_{}\".format(qt_thresh,st_thresh, q_thresh, top_k_documents, top_k_token)\n",
        "    with open('run_' + extn+ '.txt', 'w') as f:\n",
        "        f.write('')\n",
        "    with open('reranked_run_' + extn+ '.txt', 'w') as f:\n",
        "        f.write('')\n",
        "    for idx, utter in enumerate(train_utterances):\n",
        "        res, rerank = pipeline.execute(utter)\n",
        "        # write the result in the final file\n",
        "        # First write the output of the PQE and HQE\n",
        "        number = str(idx+1)\n",
        "        extn = \"{}_{}_{}_{}_{}\".format(qt_thresh,st_thresh, q_thresh, top_k_documents, top_k_token)\n",
        "        with open('run_' + extn+ '.txt', 'a') as f:\n",
        "            for idx, rec in enumerate(res):\n",
        "                score = 10\n",
        "                for idx_, i in enumerate(rec):\n",
        "                    f.write(\n",
        "                        \"{} {} {} {} {} {}\\n\".format(number + '_' + str(idx + 1),\n",
        "                                                        'Q0', i, idx_ + 1, score,\n",
        "                                                        'Automatic_run'))\n",
        "                    score *= 0.95\n",
        "        with open('reranked_run_' + extn+ '.txt', 'a') as f:\n",
        "            for idx, rec in enumerate(rerank):\n",
        "                score = 10\n",
        "                for idx_, i in enumerate(rec):\n",
        "                    f.write(\n",
        "                        \"{} {} {} {} {} {}\\n\".format(number + '_' + str(idx + 1),\n",
        "                                                        'Q0', i, idx_ + 1, score,\n",
        "                                                        'Automatic_run'))\n",
        "                    score *= 0.95\n",
        "    \n",
        "    p = Popen(\"./trec_eval/trec_eval -m ndcg ./treccastweb/2019/data/training/train_topics_mod.qrel ./reranked_run_\" + extn + \".txt|awk -F' ' '{print $NF}'\", cwd='/content/drive/MyDrive/finalproj',\n",
        "            shell=True, stdout=PIPE)\n",
        "    ndcg = p.communicate()[0].decode('ascii').strip('\\n')\n",
        "    p = Popen(\"./trec_eval/trec_eval -m ndcg ./treccastweb/2019/data/training/train_topics_mod.qrel ./run_\" + extn + \".txt|awk -F' ' '{print $NF}'\", cwd='/content/drive/MyDrive/finalproj',\n",
        "            shell=True, stdout=PIPE)\n",
        "    ndcg_ = p.communicate()[0].decode('ascii').strip('\\n')\n",
        "    return ndcg, ndcg_"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEJiMOY-VT_d"
      },
      "source": [
        "!git clone https://github.com/usnistgov/trec_eval.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyNwhDXdDOnb"
      },
      "source": [
        "!cd trec_eval && make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzNmRV9ADTSg"
      },
      "source": [
        "!ls "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIoXxaZvVW9-",
        "outputId": "f13072c1-b964-4e50-8671-05ded7b5efd4"
      },
      "source": [
        "!./trec_eval/trec_eval ../finalproj/treccastweb/2019/data/training/train_topics_mod.qrel ../finalproj/reranked_run_2_5_16_200_10.txt"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trec_eval.get_results: Cannot read results file '../finalproj/reranked_run_2_5_16_200_10.txt'\n",
            "trec_eval: Quit in file '../finalproj/reranked_run_2_5_16_200_10.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHNCJ4IfHLyo"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "optim()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajda4r-aTdkv"
      },
      "source": [
        "from hyperopt import tpe, hp, fmin, STATUS_OK, Trials, space_eval"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHn22dIvTJlS",
        "outputId": "2039bcae-5549-4f62-81b5-cf640a3b4c4d"
      },
      "source": [
        "trials = Trials()\n",
        "def opt_func(params):\n",
        "    mae = optim(qt_thresh=params['qt_thresh'], \n",
        "                st_thresh=params['st_thresh'],\n",
        "                q_thresh= params['q_thresh'],\n",
        "                top_k_documents= params['top_k_documents'],\n",
        "                top_k_token = params['top_k_token'])\n",
        "    with open(\"optimization.txt\", 'a') as f:\n",
        "        f.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(\n",
        "          params['qt_thresh'],params['st_thresh'], params['q_thresh'], params['top_k_documents'],\n",
        "            params['top_k_token'], mae[0], mae[1]\n",
        "        ))\n",
        "    return {\"loss\": -float(mae[0]),\n",
        "            \"status\": STATUS_OK}\n",
        "with open(\"optimization.txt\", 'w') as f:\n",
        "    f.write(\"\")            \n",
        "trials = Trials()\n",
        "space = {\n",
        "    'qt_thresh': hp.uniform('qt_thresh', 2, 4),\n",
        "    'st_thresh': hp.uniform('st_thresh', 2, 4),\n",
        "    'q_thresh' : hp.uniform('q_thresh', 11, 18), \n",
        "    'top_k_documents' : hp.choice('top_k_documents', [3,4,5,6,7,8,9,10]),\n",
        "    'top_k_token' : hp.choice('top_k_token', [3,4,5,6,7,8])\n",
        "}\n",
        "\n",
        "best = fmin(fn=opt_func,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=10,\n",
        "            trials=trials\n",
        "            )\n",
        "\n",
        "print(\"Best: {}\".format(best))\n",
        "print(trials.results)\n",
        "print(trials.best_trial)\n",
        "print(space_eval(space, best))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('planet', 30.055985050463484), ('earth', 20.94031031834027), ('proved', 17.97188832851041), ('core', 17.586819607258256), ('temperature', 16.665516114184342)]\n",
            "[('axis', 20.51935228818746), ('solar', 19.20696133737254), ('planet', 18.03359103027809), ('sun', 16.524966970451143), ('direction', 16.22640117447195)]\n",
            "[('planet', 24.044788040370786), ('season', 22.21498379093823), ('sun', 22.033289293934857), ('earth', 20.94031031834027), ('axis', 20.51935228818746)]\n",
            "[('planet', 30.055985050463484), ('axis', 20.51935228818746), ('solar', 19.20696133737254), ('sun', 16.524966970451143), ('direction', 16.22640117447195)]\n",
            "[('planet', 30.055985050463484), ('axis', 20.51935228818746), ('solar', 19.20696133737254), ('current', 18.533394526768397), ('crossing', 18.29884413348155)]\n",
            "[('equation', 51.38490756745931), ('chemical', 29.30477417320152), ('reaction', 23.41997566460376), ('set', 19.373101132272254), ('theory', 15.241131791633203)]\n",
            "[('chemical', 41.02668384248213), ('reaction', 40.984957413056584), ('substance', 26.964411973572933), ('equation', 19.26934033779724), ('energy', 14.943411659200208)]\n",
            "[('cell', 29.976028452976607), ('protein', 28.317210158747574), ('fluid', 20.470423300307534), ('consist', 13.773280811298202), ('diverse', 13.298660845081903)]\n",
            "  0%|          | 0/10 [05:11<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}