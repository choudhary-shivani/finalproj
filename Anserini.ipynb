{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install pyserini==0.10.0./\n",
    "\n",
    "import os, joblib\n",
    "import numpy as np\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "\n",
    "\n",
    "cast_index_loc = '/mnt/workdrive/Study/CAST/indices/index-cast2019'\n",
    "cast_data_loc = '/mnt/workdrive/Study/CAST/treccastweb/2020/2020_automatic_evaluation_topics_v1.0.json'\n",
    "tfidf_loc = '/mnt/workdrive/Study/CAST/idf_counter.pkl'\n",
    "# tfidf_loc = '/mnt/workdrive/Study/CAST/msmarco/msmarco_tfidf.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search import SimpleSearcher\n",
    "\n",
    "searcher = SimpleSearcher(cast_index_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = joblib.load(tfidf_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passage Query Expansion Module.\n",
    "# Given a query we do the followin\n",
    "# 1. First we classify utterance as implicit and explicit\n",
    "# 2. For explicit utterances we expand the query\n",
    "#\n",
    "# For explicit queries, get top-k documents to get expanded keywords.\n",
    "\n",
    "import gc, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from tf_idf_vectorizer import text_processor as idf_processor\n",
    "from utils import preprocess_utterance as preprocess_utterance\n",
    "\n",
    "\n",
    "class PQE(object):\n",
    "    def __init__(self, ir_engine, idf, top_k_documents, top_k_tokens):\n",
    "        \"\"\"\n",
    "        :param ir_engine: PySerini Backend Engine over CAST documents.\n",
    "        :param idf: Token Inverse document frequency\n",
    "        :param cfg: dict Configuration for cfg.\n",
    "        \"\"\"\n",
    "        self.backend_engine = ir_engine\n",
    "        self.idf = idf\n",
    "        self.top_k_documents = top_k_documents\n",
    "        self.top_k_tokens = top_k_tokens\n",
    "\n",
    "    def classify_utterance(self, utterance):\n",
    "        \"\"\"\n",
    "        :param utterance: str\n",
    "        :return: True if utterance to be expanded else False\n",
    "        \"\"\"\n",
    "        return True\n",
    "\n",
    "    def get_topk_token(self, documents):\n",
    "        scores = defaultdict(lambda : -1.0)\n",
    "\n",
    "        for doc in documents:\n",
    "            tokens = idf_processor(doc).split()\n",
    "            tf = Counter(tokens)\n",
    "\n",
    "            for tok in tf:\n",
    "                score = tf[tok] * self.idf.get(tok, 0)\n",
    "                if score > scores[tok]:\n",
    "                    scores[tok] = score\n",
    "\n",
    "        sorted_items = sorted(\n",
    "            scores.items(), key=lambda x: x[1], reverse=True\n",
    "        )[:self.top_k_tokens]\n",
    "\n",
    "        return set([x[0] for x in sorted_items])\n",
    "\n",
    "    def expand_query(self, utterance):\n",
    "        \"\"\"\n",
    "        :param utterance: str\n",
    "        :return query: str expanded query \n",
    "        \"\"\"\n",
    "        if not self.classify_utterance(utterance):\n",
    "            return utterance\n",
    "\n",
    "        # 1. Get top-k documents\n",
    "        results = self.backend_engine.search(utterance, k=self.top_k_documents)\n",
    "\n",
    "        if len(results) < self.top_k_documents:\n",
    "            print(f'Number of results {len(results)} are less than top-k {self.top_k_documents}.')\n",
    "            print(f'Query: {utterance}')\n",
    "\n",
    "        if len(results) == 0:\n",
    "            return utterance\n",
    "\n",
    "        documents = [res.raw for res in results]\n",
    "\n",
    "        # 2. Get TF-IDF query expansion\n",
    "        extension_set = self.get_topk_token(documents)\n",
    "\n",
    "        return utterance + \" \" + \" \".join(extension_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pqe = PQE(\n",
    "    ir_engine=searcher, idf=vectorizer,\n",
    "    top_k_documents=100, top_k_tokens=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I would like to learn about planet Jupiter migration jupiter kepler39b planets ganymede'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pqe.expand_query('I would like to learn about planet Jupiter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
